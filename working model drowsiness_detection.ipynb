{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24879,"status":"ok","timestamp":1717569187718,"user":{"displayName":"Mihir Patnaik","userId":"04408010335252768952"},"user_tz":-330},"id":"HtTztORahGov","outputId":"2de26c5c-2234-435e-b3b0-c1a4b7980dd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"rVZdcfVHgwLA","outputId":"fe4d758c-e2cf-4ebd-df3e-6a4fdc689250","executionInfo":{"status":"ok","timestamp":1717569512334,"user_tz":-330,"elapsed":320290,"user":{"displayName":"Mihir Patnaik","userId":"04408010335252768952"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting playsound\n","  Downloading playsound-1.3.0.tar.gz (7.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: playsound\n","  Building wheel for playsound (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for playsound: filename=playsound-1.3.0-py3-none-any.whl size=7020 sha256=ff012175caf93c2589e79fe97304dc921656ec58ac7984a9bccb953e8aee10b6\n","  Stored in directory: /root/.cache/pip/wheels/90/89/ed/2d643f4226fc8c7c9156fc28abd8051e2d2c0de37ae51ac45c\n","Successfully built playsound\n","Installing collected packages: playsound\n","Successfully installed playsound-1.3.0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:playsound:playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","74/74 [==============================] - 17s 205ms/step - loss: 11.3143 - accuracy: 0.6076 - val_loss: 0.5552 - val_accuracy: 0.7585\n","Epoch 2/10\n","74/74 [==============================] - 17s 231ms/step - loss: 0.5292 - accuracy: 0.8057 - val_loss: 0.4128 - val_accuracy: 0.8673\n","Epoch 3/10\n","74/74 [==============================] - 14s 196ms/step - loss: 0.4136 - accuracy: 0.8384 - val_loss: 0.2705 - val_accuracy: 0.8810\n","Epoch 4/10\n","74/74 [==============================] - 18s 246ms/step - loss: 0.3280 - accuracy: 0.8707 - val_loss: 0.2911 - val_accuracy: 0.8707\n","Epoch 5/10\n","74/74 [==============================] - 14s 188ms/step - loss: 0.2476 - accuracy: 0.9031 - val_loss: 0.3284 - val_accuracy: 0.8759\n","Epoch 6/10\n","74/74 [==============================] - 15s 199ms/step - loss: 0.2293 - accuracy: 0.9167 - val_loss: 0.2275 - val_accuracy: 0.8980\n","Epoch 7/10\n","74/74 [==============================] - 13s 180ms/step - loss: 0.1842 - accuracy: 0.9328 - val_loss: 0.2107 - val_accuracy: 0.9065\n","Epoch 8/10\n","74/74 [==============================] - 13s 178ms/step - loss: 0.1873 - accuracy: 0.9239 - val_loss: 0.1628 - val_accuracy: 0.9269\n","Epoch 9/10\n","74/74 [==============================] - 13s 170ms/step - loss: 0.1431 - accuracy: 0.9430 - val_loss: 0.2037 - val_accuracy: 0.9082\n","Epoch 10/10\n","74/74 [==============================] - 14s 195ms/step - loss: 0.1512 - accuracy: 0.9392 - val_loss: 0.1836 - val_accuracy: 0.9235\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.utils import to_categorical\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","! pip install playsound\n","from playsound import playsound\n","\n","\n","# Function to load images and labels\n","def load_images_from_folder(folder, label):\n","    images = []\n","    labels = []\n","    for filename in os.listdir(folder):\n","        img = cv2.imread(os.path.join(folder, filename))\n","        if img is not None:\n","            img = cv2.resize(img, (64, 64))\n","            images.append(img)\n","            labels.append(label)\n","    return images, labels\n","\n","# Load datasets\n","i_close_images, i_close_labels = load_images_from_folder('/content/drive/MyDrive/train/Closed', 0)\n","i_open_images, i_open_labels = load_images_from_folder('/content/drive/MyDrive/train/Open', 1)\n","yawn_images, yawn_labels = load_images_from_folder('/content/drive/MyDrive/train/yawn', 2)\n","not_yawn_images, not_yawn_labels = load_images_from_folder('/content/drive/MyDrive/train/no_yawn', 3)\n","\n","# Combine datasets\n","images = np.array(i_close_images + i_open_images + yawn_images + not_yawn_images)\n","labels = np.array(i_close_labels + i_open_labels + yawn_labels + not_yawn_labels)\n","\n","# One-hot encode the labels\n","labels = to_categorical(labels, num_classes=4)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","# Define the model\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D(pool_size=(2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(4, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n","\n","# Save the model\n","model.save('model.h5')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YQDgXyJx894"},"outputs":[],"source":["# Load the trained model\n","model = tf.keras.models.load_model('model.h5')\n","\n","# Labels for the predictions\n","labels_dict = {0: 'Closed Eyes', 1: 'Open Eyes', 2: 'Yawning', 3: 'Not Yawning'}\n","\n","# Initialize webcam\n","cap = cv2.VideoCapture(0)\n","\n","if not cap.isOpened():\n","    print(\"Error: Could not open webcam.\")\n","else:\n","    print(\"Webcam successfully opened.\")\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            print(\"Error: Failed to capture image\")\n","            break\n","\n","    # Preprocess the frame\n","    resized_frame = cv2.resize(frame, (64, 64))\n","    normalized_frame = resized_frame / 255.0\n","    input_frame = np.expand_dims(normalized_frame, axis=0)\n","\n","    # Predict the class\n","    prediction = model.predict(input_frame)\n","    class_id = np.argmax(prediction)\n","    label = labels_dict[class_id]\n","\n","    # Display the prediction\n","    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n","    cv2.imshow('Webcam', frame)\n","\n","    # Play an alert sound if necessary\n","    if class_id == 0 or class_id == 2:  # If eyes are closed or yawning\n","        playsound('/content/alarm.mp3')\n","if cv2.waitKey(1) & 0xFF == ord('q'):\n","    break\n","\n","cap.release()\n","cv2.destroyAllWindows()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RG9TucoxhEUW"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNIuQ2u65FwYyveZ3epltbK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}